### instructions

If mode is `plan`:
-   Review the provided @task under given @context, write @analysis for the rootcause of the problem, and @fix_plan to resolve the problem. Add all relevant files to the @related_files section. Update this document at the end.

If mode is `execute`:
-   If the @fix_plan is not provided, ask the user for confirmation.
-   Execute the @fix_plan.

### context

### task

```
(base) yugu@Mac src % python docs_parser/crawl_deepwiki_docs.py --url https://deepwiki.com/electron/electron --output-dir ../data/electron/deepwiki/docs
Connecting to MCP server
Connected to server with tools
Error in post_writer: Server error '500 Internal Server Error' for url 'https://mcp.deepwiki.com/sse/message?sessionId=a67a38c55d3d871d2e504398397ab4cc3f1931e25d12827fcd1aaa1b30514ff6'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500
Unknown SSE event: ping
```

crawling deepwiki doc is failing.

### analysis

`src/docs_parser/crawl_deepwiki_docs.py` opens an SSE session to `https://mcp.deepwiki.com/sse` via `MCPClient.connect_sse()` (lines 53-68) and then calls the DeepWiki tools once (lines 301-314). Both the connection handshake and `call_tool()` (lines 85-120) simply await the SSE request a single time; any `httpx.HTTPStatusError` bubbling out of `mcp.client.sse` immediately aborts the crawl. The DeepWiki MCP endpoint intermittently returns HTTP 500s from both the `/sse` handshake and `/message` writes (the log's “Error in post_writer…” matches this), so the crawler dies before saving docs. We also never inspect `CallToolResult.isError`, so even when the server responds with an error payload we proceed to index into `content[0]`, which causes follow-on crashes instead of retrying.

### fix_plan

1. Add an async retry/backoff helper inside `MCPClient` that retries transient failures (`httpx.HTTPStatusError`, `TimeoutError`, `anyio` cancellations) with exponential delays and clear logging.
2. Use that helper in `connect_sse()` so the initial tool-list handshake tolerates DeepWiki’s flaky `/sse` endpoint instead of failing immediately, and short-circuit the preflight connect if all retries fail (the crawler can still proceed straight to tool calls).
3. Update `call_tool()` / `execute_call_tool()` to reuse the same retry helper: automatically reopen the SSE session when the `/message` writer gets a 5xx and only propagate an error after exhausting retries.
4. In `pull_content_and_save()`, validate each `CallToolResult` (`isError` or missing `content`) and raise a descriptive exception before writing files so that retries or a helpful message reach the user instead of obscure index errors.
5. Re-run `python docs_parser/crawl_deepwiki_docs.py --url https://deepwiki.com/electron/electron --output-dir ../data/electron/deepwiki/docs` to confirm the crawler now survives transient 500s and materializes the markdown files.

### related_files

- src/docs_parser/crawl_deepwiki_docs.py
